{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<u> Aprendizaje Automático  </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: varname in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.13.3)\n",
      "Requirement already satisfied: executing<3.0,>=2.0 in /Users/aaronespinosa/Library/Python/3.10/lib/python/site-packages (from varname) (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3388</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.680555</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.455509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3389</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.583217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.279150</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3390</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.805500</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3391</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.416653</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3392</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.819907</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0          1001   17       1          0                  2        19.833723   \n",
       "1          1002   18       0          0                  1        15.408756   \n",
       "2          1003   15       0          2                  3         4.210570   \n",
       "3          1004   17       1          0                  3        10.028829   \n",
       "4          1005   17       1          0                  2         4.672495   \n",
       "...         ...  ...     ...        ...                ...              ...   \n",
       "2387       3388   18       1          0                  3        10.680555   \n",
       "2388       3389   17       0          0                  1         7.583217   \n",
       "2389       3390   16       1          0                  2         6.805500   \n",
       "2390       3391   16       1          1                  0        12.416653   \n",
       "2391       3392   16       1          0                  2        17.819907   \n",
       "\n",
       "      Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0            7         1                2                0       0      1   \n",
       "1            0         0                1                0       0      0   \n",
       "2           26         0                2                0       0      0   \n",
       "3           14         0                3                1       0      0   \n",
       "4           17         1                3                0       0      0   \n",
       "...        ...       ...              ...              ...     ...    ...   \n",
       "2387         2         0                4                1       0      0   \n",
       "2388         4         1                4                0       1      0   \n",
       "2389        20         0                2                0       0      0   \n",
       "2390        17         0                2                0       1      1   \n",
       "2391        13         0                2                0       0      0   \n",
       "\n",
       "      Volunteering       GPA  GradeClass  \n",
       "0                0  2.929196         2.0  \n",
       "1                0  3.042915         1.0  \n",
       "2                0  0.112602         4.0  \n",
       "3                0  2.054218         3.0  \n",
       "4                0  1.288061         4.0  \n",
       "...            ...       ...         ...  \n",
       "2387             0  3.455509         0.0  \n",
       "2388             0  3.279150         4.0  \n",
       "2389             1  1.142333         2.0  \n",
       "2390             0  1.803297         1.0  \n",
       "2391             1  2.140014         1.0  \n",
       "\n",
       "[2392 rows x 15 columns]"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from varname import nameof\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/Student_performance_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers identificados:\n",
      "      Absences\n",
      "2182      25.0\n",
      "2192      28.0\n",
      "2225      23.0\n",
      "2226      28.0\n",
      "2247      25.0\n",
      "...        ...\n",
      "2294      28.0\n",
      "2299      24.0\n",
      "2309      21.0\n",
      "2337      22.0\n",
      "2375      24.0\n",
      "\n",
      "[73 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "variables_numericas = ['Age', 'StudyTimeWeekly', 'Absences']\n",
    "df_numericas = df[variables_numericas]\n",
    "\n",
    "def identificar_outliers(df, col_categorica, col_cuantitativa):\n",
    "  outliers = pd.DataFrame() \n",
    "  \n",
    "  for categoria in df[col_categorica].unique(): \n",
    "    data_categoria = df[df[col_categorica] == categoria][col_cuantitativa] \n",
    "    Q1 = data_categoria.quantile(0.25) \n",
    "    Q3 = data_categoria.quantile(0.75) \n",
    "    IQR = Q3 - Q1 \n",
    "    limite_inferior = Q1 - 1.5 * IQR \n",
    "    limite_superior = Q3 + 1.5 * IQR \n",
    "    outliers_categoria = data_categoria[(data_categoria < limite_inferior) | (data_categoria > limite_superior)] \n",
    "    outliers = pd.concat([outliers, outliers_categoria]) \n",
    "  return outliers \n",
    "\n",
    "outliers = identificar_outliers(df, 'GradeClass', 'Absences') \n",
    "print(f\"Outliers identificados:\\n{outliers}\")\n",
    "\n",
    "indices_outliers = outliers.index\n",
    "df = df.drop(indices_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Métodos de transformación y escalado**\n",
    "\n",
    "La preparación de datos para algoritmos de machine learning es un paso importante para asegurar la fiabilidad de los modelos y aumentar su calidad.\n",
    "\n",
    "Para llevar a cabo la transformación y escalado existen diversos métodos y es fundamental comprender cuándo y como utilizarlos. Debido a la naturaleza de los datos de estudiados, el metodo a usar será el StandardScaler.\n",
    "\n",
    "* Escala los datos para que tengan una media de 0 y una desviación estandar de 1.\n",
    "* Se utiliza para centrar y escalar los valores\n",
    "* Se usa cuando los datos se distribuyen normalmente\n",
    "* Para algoritmos sensibles a la escala de los datos, como regresión lineal, regresión logística, SVM, y redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Regresión (Predecir un número cuantitativo - entero / continuo) </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.724752</td>\n",
       "      <td>0.478643</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>1.780400</td>\n",
       "      <td>-0.872110</td>\n",
       "      <td>1.523926</td>\n",
       "      <td>-0.106747</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>2.015768</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>1.101237</td>\n",
       "      <td>-0.851112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.723267</td>\n",
       "      <td>1.367334</td>\n",
       "      <td>-1.024005</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>-0.750771</td>\n",
       "      <td>0.996663</td>\n",
       "      <td>-1.701021</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>-0.997201</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>1.225776</td>\n",
       "      <td>-1.678671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.721781</td>\n",
       "      <td>-1.298737</td>\n",
       "      <td>-1.024005</td>\n",
       "      <td>1.088800</td>\n",
       "      <td>1.242403</td>\n",
       "      <td>-0.986727</td>\n",
       "      <td>1.377790</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>-0.106747</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>-1.983329</td>\n",
       "      <td>0.804006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.720296</td>\n",
       "      <td>0.478643</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>1.242403</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>-0.043200</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>0.783707</td>\n",
       "      <td>1.264822</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>0.143014</td>\n",
       "      <td>-0.023553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.718811</td>\n",
       "      <td>0.478643</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>-0.904912</td>\n",
       "      <td>0.312048</td>\n",
       "      <td>1.523926</td>\n",
       "      <td>0.783707</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>-0.696036</td>\n",
       "      <td>0.804006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>1.814396</td>\n",
       "      <td>-0.410047</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>1.088800</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>0.346227</td>\n",
       "      <td>0.430464</td>\n",
       "      <td>1.523926</td>\n",
       "      <td>1.674162</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>-0.124398</td>\n",
       "      <td>-0.023553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>1.815882</td>\n",
       "      <td>-1.298737</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>-0.750771</td>\n",
       "      <td>1.217497</td>\n",
       "      <td>-0.161615</td>\n",
       "      <td>1.523926</td>\n",
       "      <td>0.783707</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>1.517702</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>0.674042</td>\n",
       "      <td>0.804006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>1.818852</td>\n",
       "      <td>-0.410047</td>\n",
       "      <td>-1.024005</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>0.714208</td>\n",
       "      <td>-0.043200</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>-0.106747</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>0.083729</td>\n",
       "      <td>0.804006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>1.820337</td>\n",
       "      <td>1.367334</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>1.242403</td>\n",
       "      <td>0.159218</td>\n",
       "      <td>-1.464189</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>1.674162</td>\n",
       "      <td>1.264822</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>-0.432902</td>\n",
       "      <td>1.677625</td>\n",
       "      <td>-2.506231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>1.826278</td>\n",
       "      <td>-0.410047</td>\n",
       "      <td>0.976558</td>\n",
       "      <td>-0.853452</td>\n",
       "      <td>0.245816</td>\n",
       "      <td>1.423719</td>\n",
       "      <td>-0.161615</td>\n",
       "      <td>-0.656200</td>\n",
       "      <td>-0.106747</td>\n",
       "      <td>-0.790625</td>\n",
       "      <td>-0.658891</td>\n",
       "      <td>-0.496089</td>\n",
       "      <td>2.309993</td>\n",
       "      <td>0.236972</td>\n",
       "      <td>-1.678671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2319 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID       Age    Gender  Ethnicity  ParentalEducation  \\\n",
       "0     -1.724752  0.478643  0.976558  -0.853452           0.245816   \n",
       "1     -1.723267  1.367334 -1.024005  -0.853452          -0.750771   \n",
       "2     -1.721781 -1.298737 -1.024005   1.088800           1.242403   \n",
       "3     -1.720296  0.478643  0.976558  -0.853452           1.242403   \n",
       "4     -1.718811  0.478643  0.976558  -0.853452           0.245816   \n",
       "...         ...       ...       ...        ...                ...   \n",
       "2314   1.814396 -0.410047  0.976558   1.088800           0.245816   \n",
       "2315   1.815882 -1.298737  0.976558  -0.853452          -0.750771   \n",
       "2316   1.818852 -0.410047 -1.024005  -0.853452           0.245816   \n",
       "2317   1.820337  1.367334  0.976558  -0.853452           1.242403   \n",
       "2318   1.826278 -0.410047  0.976558  -0.853452           0.245816   \n",
       "\n",
       "      StudyTimeWeekly  Absences  Tutoring  ParentalSupport  Extracurricular  \\\n",
       "0            1.780400 -0.872110  1.523926        -0.106747        -0.790625   \n",
       "1            0.996663 -1.701021 -0.656200        -0.997201        -0.790625   \n",
       "2           -0.986727  1.377790 -0.656200        -0.106747        -0.790625   \n",
       "3            0.043786 -0.043200 -0.656200         0.783707         1.264822   \n",
       "4           -0.904912  0.312048  1.523926         0.783707        -0.790625   \n",
       "...               ...       ...       ...              ...              ...   \n",
       "2314         0.346227  0.430464  1.523926         1.674162        -0.790625   \n",
       "2315         1.217497 -0.161615  1.523926         0.783707        -0.790625   \n",
       "2316         0.714208 -0.043200 -0.656200        -0.106747        -0.790625   \n",
       "2317         0.159218 -1.464189 -0.656200         1.674162         1.264822   \n",
       "2318         1.423719 -0.161615 -0.656200        -0.106747        -0.790625   \n",
       "\n",
       "        Sports     Music  Volunteering       GPA  GradeClass  \n",
       "0    -0.658891  2.015768     -0.432902  1.101237   -0.851112  \n",
       "1    -0.658891 -0.496089     -0.432902  1.225776   -1.678671  \n",
       "2    -0.658891 -0.496089     -0.432902 -1.983329    0.804006  \n",
       "3    -0.658891 -0.496089     -0.432902  0.143014   -0.023553  \n",
       "4    -0.658891 -0.496089     -0.432902 -0.696036    0.804006  \n",
       "...        ...       ...           ...       ...         ...  \n",
       "2314 -0.658891 -0.496089     -0.432902 -0.124398   -0.023553  \n",
       "2315  1.517702 -0.496089     -0.432902  0.674042    0.804006  \n",
       "2316 -0.658891 -0.496089     -0.432902  0.083729    0.804006  \n",
       "2317 -0.658891 -0.496089     -0.432902  1.677625   -2.506231  \n",
       "2318 -0.658891 -0.496089      2.309993  0.236972   -1.678671  \n",
       "\n",
       "[2319 rows x 15 columns]"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uso del StandardScaler en las columnas numericas\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
    "df_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.992773</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732299</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.771270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760729</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.210718</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.501965</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513555</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322015</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.587442</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452509</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.833683</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634778</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>0.997909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.691442</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>0.998327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.534589</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863877</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.891967</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535003</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2319 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID       Age  Gender  Ethnicity  ParentalEducation  \\\n",
       "0      0.000000  0.666667     1.0   0.000000               0.50   \n",
       "1      0.000418  1.000000     0.0   0.000000               0.25   \n",
       "2      0.000836  0.000000     0.0   0.666667               0.75   \n",
       "3      0.001255  0.666667     1.0   0.000000               0.75   \n",
       "4      0.001673  0.666667     1.0   0.000000               0.50   \n",
       "...         ...       ...     ...        ...                ...   \n",
       "2314   0.996654  0.333333     1.0   0.666667               0.50   \n",
       "2315   0.997072  0.000000     1.0   0.000000               0.25   \n",
       "2316   0.997909  0.333333     0.0   0.000000               0.50   \n",
       "2317   0.998327  1.000000     1.0   0.000000               0.75   \n",
       "2318   1.000000  0.333333     1.0   0.000000               0.50   \n",
       "\n",
       "      StudyTimeWeekly  Absences  Tutoring  ParentalSupport  Extracurricular  \\\n",
       "0            0.992773  0.241379       1.0             0.50              0.0   \n",
       "1            0.771270  0.000000       0.0             0.25              0.0   \n",
       "2            0.210718  0.896552       0.0             0.50              0.0   \n",
       "3            0.501965  0.482759       0.0             0.75              1.0   \n",
       "4            0.233840  0.586207       1.0             0.75              0.0   \n",
       "...               ...       ...       ...              ...              ...   \n",
       "2314         0.587442  0.620690       1.0             1.00              0.0   \n",
       "2315         0.833683  0.448276       1.0             0.75              0.0   \n",
       "2316         0.691442  0.482759       0.0             0.50              0.0   \n",
       "2317         0.534589  0.068966       0.0             1.00              1.0   \n",
       "2318         0.891967  0.448276       0.0             0.50              0.0   \n",
       "\n",
       "      Sports  Music  Volunteering       GPA  GradeClass  \n",
       "0        0.0    1.0           0.0  0.732299        0.50  \n",
       "1        0.0    0.0           0.0  0.760729        0.25  \n",
       "2        0.0    0.0           0.0  0.028151        1.00  \n",
       "3        0.0    0.0           0.0  0.513555        0.75  \n",
       "4        0.0    0.0           0.0  0.322015        1.00  \n",
       "...      ...    ...           ...       ...         ...  \n",
       "2314     0.0    0.0           0.0  0.452509        0.75  \n",
       "2315     1.0    0.0           0.0  0.634778        1.00  \n",
       "2316     0.0    0.0           0.0  0.500021        1.00  \n",
       "2317     0.0    0.0           0.0  0.863877        0.00  \n",
       "2318     0.0    0.0           1.0  0.535003        0.25  \n",
       "\n",
       "[2319 rows x 15 columns]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_dict):\n",
    "    results = []\n",
    "\n",
    "    for name, (mse, r2, mae, rmse, pred) in model_dict.items():\n",
    "        stats = [name, mse, r2, mae, rmse, pred]\n",
    "        results.append(stats)\n",
    "    # df_results = pd.DataFrame(results, columns=['Modelo', 'Error Cuadrático Medio (MSE)', 'Coeficiente de Determinación (R^2)', 'Predicciones'])\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'MSE', 'R2', 'MAE', 'RMSE', 'Predicciones'])\n",
    "    return df_results\n",
    "\n",
    "def gen_graph(x, y_pred, x_name, y_name, title):\n",
    "    plt.figure(figsize=(14,7))\n",
    "\n",
    "    sns.scatterplot(data=df, x=x_name, y=y_name)\n",
    "    plt.plot(x, y_pred, color='red', label='Recta de regresión')\n",
    "    plt.title(title)\n",
    "    plt.savefig('./graph/' + title + '.png')\n",
    "    print(y_pred.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresión lineal\n",
    "def regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Añadir jitter a los datos binomiales\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[0].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[0].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[1].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[1].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Normalizar los datos de y si el rango es muy pequeño\n",
    "    if np.max(y_train) - np.min(y_train) < 0.1:\n",
    "        scaler = MinMaxScaler()\n",
    "        y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
    "        y_pred_train = scaler.transform(y_pred_train.reshape(-1, 1)).flatten()\n",
    "        y_pred_test = scaler.transform(y_pred_test.reshape(-1, 1)).flatten()\n",
    "        y_n = f'Normalizado {y_n}'\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Asegurarse de que X y y sean arrays unidimensionales\n",
    "        X = X.flatten()\n",
    "        y = y.flatten()\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X)\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "        y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "        # Ajustar tamaño de la ventana para datos con poco rango\n",
    "        window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "        if len(y_sorted) <= window_size:\n",
    "            window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "        \n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la recta de regresión\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', label='Recta de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train, y_pred_train, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test, y_pred_test, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# def regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "#     # Crear un modelo de regresión lineal\n",
    "#     model = LinearRegression()\n",
    "\n",
    "#     # Ajustar el modelo a los datos\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Hacer predicciones para todos los valores de X\n",
    "#     y_pred_train = model.predict(X_train)\n",
    "#     y_pred_test = model.predict(X_test)\n",
    "\n",
    "#     # Calcular métricas\n",
    "#     mse = mean_squared_error(y_test, y_pred_test)\n",
    "#     r2 = r2_score(y_test, y_pred_test)\n",
    "#     mae = mean_absolute_error(y_test, y_pred_test)\n",
    "#     rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "#     # Preparar datos para gráficos\n",
    "#     train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "#     test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "    \n",
    "#     # Generar gráfico\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "#     def boxplot_with_regression(ax, data, title):\n",
    "#         X = data[:, 0].reshape(-1, 1)\n",
    "#         y = data[:, 1]\n",
    "\n",
    "#         # Graficar el gráfico de cajas\n",
    "#         sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "#         # Graficar la línea de regresión\n",
    "#         ax.scatter(X.flatten(), y, color='black', alpha=0.5, label='Datos')\n",
    "#         sorted_indices = np.argsort(X.flatten())\n",
    "#         X_sorted = X[sorted_indices]\n",
    "#         y_pred_sorted = model.predict(X_sorted)\n",
    "#         ax.plot(X_sorted, y_pred_sorted, color='red', linewidth=2, label='Línea de Regresión')\n",
    "\n",
    "#         # Configuración del gráfico\n",
    "#         ax.set_title(title)\n",
    "#         ax.set_xlabel(f'{x_n}')\n",
    "#         ax.set_ylabel(f'{y_n}')\n",
    "#         ax.legend()\n",
    "#         ax.grid(True)\n",
    "\n",
    "#     # Primer subgráfico: Datos de train\n",
    "#     boxplot_with_regression(ax[0], train_data, f'Regresión Lineal - Train: {x_n} vs {y_n}')\n",
    "\n",
    "#     # Segundo subgráfico: Datos de test\n",
    "#     boxplot_with_regression(ax[1], test_data, f'Regresión Lineal - Test: {x_n} vs {y_n}')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     return mse, r2, mae, rmse, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el primer hasta el último cuadro\n",
    "        X_new = np.linspace(box_limits[0], box_limits[1], 100).reshape(-1, 1)\n",
    "        y_pred_new = model.predict(X_new)\n",
    "\n",
    "        # Graficar la línea de regresión\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Línea de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    else:\n",
    "        return regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_polinomica_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=15)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "    \n",
    "    # Crear el modelo de regresión polinómica\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtener el valor mínimo y máximo de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Crear un rango de valores para x para dibujar la curva de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_test, y_test_jitter, color='green', label='Datos de test', alpha=0.5)\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar el gráfico en la carpeta correspondiente\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_polinomica_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtener el valor mínimo y máximo de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Crear un rango de valores para x para dibujar la curva de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Asegurarse de que X y y sean arrays unidimensionales\n",
    "        X = X.flatten()\n",
    "        y = y.flatten()\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X)\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "        y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "        # Ajustar tamaño de la ventana para datos con poco rango\n",
    "        window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "        if len(y_sorted) <= window_size:\n",
    "            window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "        \n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la curva polinómica de regresión\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', label='Curva polinómica de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train_jitter, y_poly_pred_train, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test_jitter, y_poly_pred_test, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar el gráfico en la carpeta correspondiente\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_polinomica_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # Obtener los valores mínimos y máximos de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Ajustar los límites de la línea de regresión para comenzar y terminar en las cajas\n",
    "        x_start = max(x_min, box_limits[0])\n",
    "        x_end = min(x_max, box_limits[1])\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el borde de la primera caja hasta el borde de la última caja\n",
    "        X_new = np.linspace(x_start, x_end, 100).reshape(-1, 1)\n",
    "        y_pred_new = model.predict(poly.transform(X_new))\n",
    "\n",
    "        # Graficar la curva de regresión polinómica\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Curva Polinómica de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_polinomica_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_polinomica_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    else:\n",
    "        return regresion_polinomica_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def gen_graph_neuron(x_train, y_train, x_test, y_test, y_pred_train, y_pred_test, x_n, y_n, title, model):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Crear una figura con dos subgráficos\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  \n",
    "\n",
    "    # Obtener los valores mínimo y máximo de x para la línea de predicción\n",
    "    x_min = min(x_train.min(), x_test.min())\n",
    "    x_max = max(x_train.max(), x_test.max())\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "\n",
    "    # Normalizar el rango de x para las predicciones\n",
    "    x_range_norm = (x_range - np.mean(x_train)) / np.std(x_train)\n",
    "\n",
    "    # Realizar las predicciones para el rango de valores\n",
    "    y_range_pred_norm = model.predict(x_range_norm)\n",
    "    y_range_pred = y_range_pred_norm * np.std(y_train) + np.mean(y_train)\n",
    "\n",
    "    # Primer subgráfico: Datos de entrenamiento\n",
    "    ax[0].scatter(x_train, y_train, label='Datos de entrenamiento')\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'3. REGRESIÓN NEURONAL Modelo de red neuronal de {x_n} y {y_n} - Datos de training')\n",
    "    ax[0].set_xlabel(x_n)\n",
    "    ax[0].set_ylabel(y_n)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de prueba\n",
    "    ax[1].scatter(x_test, y_test, color='green', label='Datos de prueba')\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'3. REGRESIÓN NEURONAL Modelo de red neuronal de {x_n} y {y_n} - Datos de test')\n",
    "    ax[1].set_xlabel(x_n)\n",
    "    ax[1].set_ylabel(y_n)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def regresion_neuronal(x, y, x_n, y_n):\n",
    "    # Convertir las Series a numpy arrays y asegurarse de que sean vectores columna\n",
    "    x = np.array(x).reshape(-1, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Normalizar los datos de entrada\n",
    "    x_mean = np.mean(x)\n",
    "    x_std = np.std(x)\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    x_norm = (x - x_mean) / x_std\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_norm, y_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear el modelo de la red neuronal\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Hacer predicciones en los datos normalizados\n",
    "    y_pred_train_norm = model.predict(x_train)\n",
    "    y_pred_test_norm = model.predict(x_test)\n",
    "    y_pred_all_norm = model.predict(x_norm)\n",
    "\n",
    "    # Desnormalizar las predicciones\n",
    "    y_pred_train = y_pred_train_norm * y_std + y_mean\n",
    "    y_pred_test = y_pred_test_norm * y_std + y_mean\n",
    "    y_pred_all = y_pred_all_norm * y_std + y_mean\n",
    "\n",
    "    # Desnormalizar los datos de prueba y entrenamiento para la visualización\n",
    "    x_train_orig = x_train * x_std + x_mean\n",
    "    x_test_orig = x_test * x_std + x_mean\n",
    "    x_all_orig = x_norm * x_std + x_mean\n",
    "\n",
    "    y_train_orig = y_train * y_std + y_mean\n",
    "    y_test_orig = y_test * y_std + y_mean\n",
    "    y_all_orig = y_norm * y_std + y_mean\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse = mean_squared_error(y_all_orig, y_pred_all)\n",
    "    r2 = r2_score(y_all_orig, y_pred_all)\n",
    "    mae = mean_absolute_error(y_all_orig, y_pred_all)\n",
    "    rmse = mean_squared_error(y_all_orig, y_pred_all, squared=False)\n",
    "\n",
    "    # Generar gráficos para datos de entrenamiento y prueba\n",
    "    gen_graph_neuron(x_train_orig, y_train_orig, x_test_orig, y_test_orig, y_pred_train, y_pred_test, x_n, y_n, 'Modelo de red neuronal', model)\n",
    "\n",
    "    return mse, r2, mae, rmse, y_pred_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def gen_graph_neuron(x_train, y_train, x_test, y_test, y_pred_train, y_pred_test, x_n, y_n, title, model):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  \n",
    "\n",
    "    x_min = min(x_train.min(), x_test.min())\n",
    "    x_max = max(x_train.max(), x_test.max())\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "\n",
    "    x_range_norm = (x_range - np.mean(x_train)) / np.std(x_train)\n",
    "    y_range_pred_norm = model.predict(x_range_norm)\n",
    "    y_range_pred = y_range_pred_norm * np.std(y_train) + np.mean(y_train)\n",
    "\n",
    "    ax[0].scatter(x_train, y_train, label='Datos de entrenamiento')\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'{title} - Datos de entrenamiento')\n",
    "    ax[0].set_xlabel(x_n)\n",
    "    ax[0].set_ylabel(y_n)\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].scatter(x_test, y_test, color='green', label='Datos de prueba')\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'{title} - Datos de prueba')\n",
    "    ax[1].set_xlabel(x_n)\n",
    "    ax[1].set_ylabel(y_n)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def regresion_neuronal(x, y, x_n, y_n):\n",
    "    x = np.array(x).reshape(-1, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    x_mean = np.mean(x)\n",
    "    x_std = np.std(x)\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    x_norm = (x - x_mean) / x_std\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_norm, y_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.2, verbose=0)\n",
    "\n",
    "    y_pred_train_norm = model.predict(x_train)\n",
    "    y_pred_test_norm = model.predict(x_test)\n",
    "    y_pred_all_norm = model.predict(x_norm)\n",
    "\n",
    "    y_pred_train = y_pred_train_norm * y_std + y_mean\n",
    "    y_pred_test = y_pred_test_norm * y_std + y_mean\n",
    "    y_pred_all = y_pred_all_norm * y_std + y_mean\n",
    "\n",
    "    x_train_orig = x_train * x_std + x_mean\n",
    "    x_test_orig = x_test * x_std + x_mean\n",
    "    x_all_orig = x_norm * x_std + x_mean\n",
    "\n",
    "    y_train_orig = y_train * y_std + y_mean\n",
    "    y_test_orig = y_test * y_std + y_mean\n",
    "    y_all_orig = y_norm * y_std + y_mean\n",
    "\n",
    "    mse = mean_squared_error(y_all_orig, y_pred_all)\n",
    "    r2 = r2_score(y_all_orig, y_pred_all)\n",
    "    mae = mean_absolute_error(y_all_orig, y_pred_all)\n",
    "    rmse = mean_squared_error(y_all_orig, y_pred_all, squared=False)\n",
    "\n",
    "    gen_graph_neuron(x_train_orig, y_train_orig, x_test_orig, y_test_orig, y_pred_train, y_pred_test, x_n, y_n, 'Modelo de red neuronal', model)\n",
    "\n",
    "    return mse, r2, mae, rmse, y_pred_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_neuronal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtener el valor mínimo y máximo de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Crear un rango de valores para x para dibujar la curva de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Asegurarse de que X y y sean arrays unidimensionales\n",
    "        X = X.flatten()\n",
    "        y = y.flatten()\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X)\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "        y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "        # Ajustar tamaño de la ventana para datos con poco rango\n",
    "        window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "        if len(y_sorted) <= window_size:\n",
    "            window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "        \n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la curva polinómica de regresión\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', label='Curva polinómica de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train_jitter, y_poly_pred_train, f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test_jitter, y_poly_pred_test, f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar el gráfico en la carpeta correspondiente\n",
    "    file = str(f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_neuronal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # Obtener los valores mínimos y máximos de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Ajustar los límites de la línea de regresión para comenzar y terminar en las cajas\n",
    "        x_start = max(x_min, box_limits[0])\n",
    "        x_end = min(x_max, box_limits[1])\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el borde de la primera caja hasta el borde de la última caja\n",
    "        X_new = np.linspace(x_start, x_end, 100).reshape(-1, 1)\n",
    "        y_pred_new = model.predict(poly.transform(X_new))\n",
    "\n",
    "        # Graficar la curva de regresión polinómica\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Curva Polinómica de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'3. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n",
    "\n",
    "def regresion_neuronal(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        # return regresion_neuronal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "        return 0, 0, 0, 0, 0\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        # return regresion_neuronal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "        return 0, 0, 0, 0, 0\n",
    "    else:\n",
    "        return regresion_neuronal_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "regresion_neuronal() missing 3 required positional arguments: 'x_n', 'y_n', and 'df_n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1014], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Dividir los datos en conjuntos de entrenamiento y prueba\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(x\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m     models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;66;03m#'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# 'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegresión Neuronal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mregresion_neuronal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m     comparison \u001b[38;5;241m=\u001b[39m compare_models(models)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y_n \u001b[38;5;129;01min\u001b[39;00m variables:\n",
      "\u001b[0;31mTypeError\u001b[0m: regresion_neuronal() missing 3 required positional arguments: 'x_n', 'y_n', and 'df_n'"
     ]
    }
   ],
   "source": [
    "x_n = 'GPA'\n",
    "variables = [\"StudyTimeWeekly\", \"Absences\", \"ParentalSupport\", \"Tutoring\", \"Extracurricular\", \"Sports\", \"Music\"]\n",
    "\n",
    "for y_n in variables:\n",
    "    x = pd.Series(df[x_n])\n",
    "    y = pd.Series(df[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {#'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\n",
    "    # 'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n)),\n",
    "    }\n",
    "    comparison = compare_models(models)\n",
    "\n",
    "for y_n in variables:\n",
    "    x = pd.Series(df_standard[x_n])\n",
    "    y = pd.Series(df_standard[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {#'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_standard)),\n",
    "    # 'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_standard)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n)),\n",
    "    }\n",
    "    comparison = compare_models(models)\n",
    "\n",
    "for y_n in variables:\n",
    "    x = pd.Series(df_minmax[x_n])\n",
    "    y = pd.Series(df_minmax[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {#'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_minmax)),\n",
    "    # 'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_minmax)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n)),\n",
    "    }\n",
    "    comparison = compare_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Cargar una paleta de colores de seaborn\n",
    "# palette = sns.color_palette(\"husl\", n_colors=len(comparison))\n",
    "\n",
    "# def get_color(index):\n",
    "#     return palette[index]\n",
    "\n",
    "# comparison = comparison.iloc[::-1]\n",
    "\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# sns.scatterplot(data=df, x=x_n,  y=y_n, label='Datos originales')\n",
    "\n",
    "# # Agregar las predicciones de cada modelo\n",
    "# for index, row in comparison.iterrows():\n",
    "#     Modelo = row['Modelo']\n",
    "#     mse = row['MSE']\n",
    "#     r2 = row['R2']\n",
    "#     mae = row['MAE']\n",
    "#     rmse = row['RMSE']\n",
    "    \n",
    "#     y_pred = row['Predicciones']\n",
    "#     # plt.plot(x, y_pred, color=random_color(), label=f'{Modelo} (MSE: {mse:.2f}, R2: {r2:.2f})')\n",
    "#     plt.plot(x, y_pred, color=get_color(index), label=f'{Modelo}')\n",
    "\n",
    "\n",
    "# plt.title('Comparación de Modelos de Regresión')\n",
    "# plt.xlabel('GPA')\n",
    "# plt.ylabel('Absences')\n",
    "# plt.legend()\n",
    "# plt.savefig('./graph/Comparacion_de_Modelos_de_Regression.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Clasificación (Predecir una clase - binaria / multinomial) </u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_class(model_dict):\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    for name, (confusion, exactitud, precision, sensibilidad, f1) in model_dict.items():\n",
    "        stats = [name, exactitud, precision, sensibilidad, f1]\n",
    "        results.append(stats)\n",
    "        confusion_matrices[name] = confusion    \n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    return df_results, confusion_matrices\n",
    "\n",
    "def gen_graph_class(df_metricas):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Accuracy', data=df_metricas, ax=ax[0, 0])\n",
    "    ax[0, 0].set_title('Exactitud')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Precision', data=df_metricas, ax=ax[0, 1])\n",
    "    ax[0, 1].set_title('Precision')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Recall', data=df_metricas, ax=ax[1, 0])\n",
    "    ax[1, 0].set_title('Recall')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='F1 Score', data=df_metricas, ax=ax[1, 1])\n",
    "    ax[1, 1].set_title('F1 Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./graph/Modelos de Clasificacion.png')\n",
    "    plt.show()\n",
    "\n",
    "def gen_confusion_matrix(confusion_matrices):\n",
    "    for model_name, confusion in confusion_matrices.items():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Matriz de Confusión - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(f'./graph/Matriz de Confusión - {model_name}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    modelo = RandomForestClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maquina_vectores_soporte(X_train, X_test, y_train, y_test):\n",
    "    modelo = SVC()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbol_decision(X_train, X_test, y_train, y_test):\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def red_neuronal_clasificacion(X_train, X_test, y_train, y_test):\n",
    "    # Determinar el número de clases a partir de los datos\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Convertir etiquetas a formato categórico (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(64, input_dim=input_dim, activation='relu'))  # Capa oculta con 64 neuronas\n",
    "    modelo.add(Dense(64, activation='relu'))  # Otra capa oculta con 64 neuronas\n",
    "    modelo.add(Dense(num_classes, activation='softmax'))  # Capa de salida\n",
    "\n",
    "    # Compilar el modelo\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train_cat, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred_cat = modelo.predict(X_test)\n",
    "    y_pred = y_pred_cat.argmax(axis=1)  # Convertir one-hot encoding a etiquetas\n",
    "\n",
    "    # Calcular métricas\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return confusion, exactitud, precision, sensibilidad, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresión_logistica(X_train, X_test, y_train, y_test):\n",
    "    modelo = LogisticRegression()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(X_train, X_test, y_train, y_test):\n",
    "    modelo = KNeighborsClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    modelo = GaussianNB()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'ParentalEducation'\n",
    "y_n = 'GradeClass'\n",
    "\n",
    "X = df[[x_n]].values\n",
    "y = df[y_n].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Random Forest': random_forest(X_train, X_test, y_train, y_test),\n",
    "    'Máquina de Vectores de Soporte': maquina_vectores_soporte(X_train, X_test, y_train, y_test),\n",
    "    'Árbol de Decisión': arbol_decision(X_train, X_test, y_train, y_test),\n",
    "    'Red Neuronal' : red_neuronal_clasificacion(X_train, X_test, y_train, y_test),\n",
    "    'Regresión Logística': regresión_logistica(X_train, X_test, y_train, y_test),\n",
    "    'K-Nearest Neighbors': k_nearest(X_train, X_test, y_train, y_test),\n",
    "    'Naive Bayes': naive_bayes(X_train, X_test, y_train, y_test)\n",
    "}\n",
    "\n",
    "comparison, confusion_matrices = compare_models_class(models)\n",
    "gen_graph_class(comparison)\n",
    "gen_confusion_matrix(confusion_matrices)\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
