{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<u> Aprendizaje Automático  </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('./data/Student_performance_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_numericas = ['Age', 'StudyTimeWeekly', 'Absences']\n",
    "df_numericas = df[variables_numericas]\n",
    "\n",
    "def identificar_outliers(df, col_categorica, col_cuantitativa):\n",
    "  outliers = pd.DataFrame() \n",
    "  \n",
    "  for categoria in df[col_categorica].unique(): \n",
    "    data_categoria = df[df[col_categorica] == categoria][col_cuantitativa] \n",
    "    Q1 = data_categoria.quantile(0.25) \n",
    "    Q3 = data_categoria.quantile(0.75) \n",
    "    IQR = Q3 - Q1 \n",
    "    limite_inferior = Q1 - 1.5 * IQR \n",
    "    limite_superior = Q3 + 1.5 * IQR \n",
    "    outliers_categoria = data_categoria[(data_categoria < limite_inferior) | (data_categoria > limite_superior)] \n",
    "    outliers = pd.concat([outliers, outliers_categoria]) \n",
    "  return outliers \n",
    "\n",
    "outliers = identificar_outliers(df, 'GradeClass', 'Absences') \n",
    "print(f\"Outliers identificados:\\n{outliers}\")\n",
    "\n",
    "indices_outliers = outliers.index\n",
    "df = df.drop(indices_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Métodos de transformación y escalado**\n",
    "\n",
    "La preparación de datos para algoritmos de machine learning es un paso importante para asegurar la fiabilidad de los modelos y aumentar su calidad.\n",
    "\n",
    "Para llevar a cabo la transformación y escalado existen diversos métodos y es fundamental comprender cuándo y como utilizarlos. Debido a la naturaleza de los datos de estudiados, el metodo a usar será el StandardScaler.\n",
    "\n",
    "* Escala los datos para que tengan una media de 0 y una desviación estandar de 1.\n",
    "* Se utiliza para centrar y escalar los valores\n",
    "* Se usa cuando los datos se distribuyen normalmente\n",
    "* Para algoritmos sensibles a la escala de los datos, como regresión lineal, regresión logística, SVM, y redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Regresión (Predecir un número cuantitativo - entero / continuo) </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del StandardScaler en las columnas numericas\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_numericas = scaler_standard.fit_transform(df_numericas)\n",
    "df_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_dict):\n",
    "    results = []\n",
    "\n",
    "    for name, (mse, r2, mae, rmse, pred) in model_dict.items():\n",
    "        stats = [name, mse, r2, mae, rmse, pred]\n",
    "        results.append(stats)\n",
    "    # df_results = pd.DataFrame(results, columns=['Modelo', 'Error Cuadrático Medio (MSE)', 'Coeficiente de Determinación (R^2)', 'Predicciones'])\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'MSE', 'R2', 'MAE', 'RMSE', 'Predicciones'])\n",
    "    return df_results\n",
    "\n",
    "def gen_graph(x, y_pred, x_name, y_name, title):\n",
    "    plt.figure(figsize=(14,7))\n",
    "\n",
    "    sns.scatterplot(data=df, x=x_name, y=y_name)\n",
    "    plt.plot(x, y_pred, color='red', label='Recta de regresión')\n",
    "    plt.title(title)\n",
    "    plt.savefig('./graph/' + title + '.png')\n",
    "    print(y_pred.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresión lineal\n",
    "def regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Añadir jitter a los datos binomiales\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[0].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[0].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[1].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[1].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresión lineal\n",
    "def regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X, axis=0).flatten()\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "\n",
    "        # Calcular las proporciones de 0s y 1s en ventanas móviles\n",
    "        window_size = 50\n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] == 0) for i in range(len(y_sorted) - window_size)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] == 1) for i in range(len(y_sorted) - window_size)]\n",
    "        X_windows = X_sorted[:len(X_sorted) - window_size]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'No {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'{y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la recta de regresión\n",
    "        ax.plot(X_sorted, y_pred[sorted_indices], color='red', label='Recta de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train, y_pred_train, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test, y_pred_test, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# def regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "#     # Crear un modelo de regresión lineal\n",
    "#     model = LinearRegression()\n",
    "\n",
    "#     # Ajustar el modelo a los datos\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Hacer predicciones para todos los valores de X\n",
    "#     y_pred_train = model.predict(X_train)\n",
    "#     y_pred_test = model.predict(X_test)\n",
    "\n",
    "#     # Calcular métricas\n",
    "#     mse = mean_squared_error(y_test, y_pred_test)\n",
    "#     r2 = r2_score(y_test, y_pred_test)\n",
    "#     mae = mean_absolute_error(y_test, y_pred_test)\n",
    "#     rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "#     # Preparar datos para gráficos\n",
    "#     train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "#     test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "    \n",
    "#     # Generar gráfico\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "#     def boxplot_with_regression(ax, data, title):\n",
    "#         X = data[:, 0].reshape(-1, 1)\n",
    "#         y = data[:, 1]\n",
    "\n",
    "#         # Graficar el gráfico de cajas\n",
    "#         sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "#         # Graficar la línea de regresión\n",
    "#         ax.scatter(X.flatten(), y, color='black', alpha=0.5, label='Datos')\n",
    "#         sorted_indices = np.argsort(X.flatten())\n",
    "#         X_sorted = X[sorted_indices]\n",
    "#         y_pred_sorted = model.predict(X_sorted)\n",
    "#         ax.plot(X_sorted, y_pred_sorted, color='red', linewidth=2, label='Línea de Regresión')\n",
    "\n",
    "#         # Configuración del gráfico\n",
    "#         ax.set_title(title)\n",
    "#         ax.set_xlabel(f'{x_n}')\n",
    "#         ax.set_ylabel(f'{y_n}')\n",
    "#         ax.legend()\n",
    "#         ax.grid(True)\n",
    "\n",
    "#     # Primer subgráfico: Datos de train\n",
    "#     boxplot_with_regression(ax[0], train_data, f'Regresión Lineal - Train: {x_n} vs {y_n}')\n",
    "\n",
    "#     # Segundo subgráfico: Datos de test\n",
    "#     boxplot_with_regression(ax[1], test_data, f'Regresión Lineal - Test: {x_n} vs {y_n}')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     return mse, r2, mae, rmse, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Graficar la línea de regresión\n",
    "        sorted_indices = np.argsort(X.flatten())\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_pred_sorted = model.predict(X_sorted)\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', linewidth=2, label='Línea de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'Regresión Lineal - Train: {x_n} vs {y_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'Regresión Lineal - Test: {x_n} vs {y_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n)\n",
    "    else:\n",
    "        return regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_binomial(X_train, X_test, y_train, y_test, x_n, y_n):\n",
    "    \n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=15)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "    \n",
    "    # Crear el modelo de regresión polinómica\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.fit_transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "   # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtenemos el valor mínimo y máximo de x\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Creamos un rango de valores para x para dibujar la línea de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    title = 'Modelo de regresión polinómica para predecir los resultados'\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train, label='Datos de train')\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_test, y_test, color='green', label='Datos de test')\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def gen_graph_neuron(x_train, y_train, x_test, y_test, y_pred_train, y_pred_test, x_n, y_n, title, model):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Crear una figura con dos subgráficos\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  \n",
    "\n",
    "    # Obtener los valores mínimo y máximo de x para la línea de predicción\n",
    "    x_min = min(x_train.min(), x_test.min())\n",
    "    x_max = max(x_train.max(), x_test.max())\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "\n",
    "    # Normalizar el rango de x para las predicciones\n",
    "    x_range_norm = (x_range - np.mean(x_train)) / np.std(x_train)\n",
    "\n",
    "    # Realizar las predicciones para el rango de valores\n",
    "    y_range_pred_norm = model.predict(x_range_norm)\n",
    "    y_range_pred = y_range_pred_norm * np.std(y_train) + np.mean(y_train)\n",
    "\n",
    "    # Primer subgráfico: Datos de entrenamiento\n",
    "    ax[0].scatter(x_train, y_train, label='Datos de entrenamiento')\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'3. REGRESIÓN NEURONAL Modelo de red neuronal de {x_n} y {y_n} - Datos de training')\n",
    "    ax[0].set_xlabel(x_n)\n",
    "    ax[0].set_ylabel(y_n)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de prueba\n",
    "    ax[1].scatter(x_test, y_test, color='green', label='Datos de prueba')\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'3. REGRESIÓN NEURONAL Modelo de red neuronal de {x_n} y {y_n} - Datos de test')\n",
    "    ax[1].set_xlabel(x_n)\n",
    "    ax[1].set_ylabel(y_n)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def regresion_neuronal(x, y, x_n, y_n):\n",
    "    # Convertir las Series a numpy arrays y asegurarse de que sean vectores columna\n",
    "    x = np.array(x).reshape(-1, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Normalizar los datos de entrada\n",
    "    x_mean = np.mean(x)\n",
    "    x_std = np.std(x)\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    x_norm = (x - x_mean) / x_std\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_norm, y_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Crear el modelo de la red neuronal\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Hacer predicciones en los datos normalizados\n",
    "    y_pred_train_norm = model.predict(x_train)\n",
    "    y_pred_test_norm = model.predict(x_test)\n",
    "    y_pred_all_norm = model.predict(x_norm)\n",
    "\n",
    "    # Desnormalizar las predicciones\n",
    "    y_pred_train = y_pred_train_norm * y_std + y_mean\n",
    "    y_pred_test = y_pred_test_norm * y_std + y_mean\n",
    "    y_pred_all = y_pred_all_norm * y_std + y_mean\n",
    "\n",
    "    # Desnormalizar los datos de prueba y entrenamiento para la visualización\n",
    "    x_train_orig = x_train * x_std + x_mean\n",
    "    x_test_orig = x_test * x_std + x_mean\n",
    "    x_all_orig = x_norm * x_std + x_mean\n",
    "\n",
    "    y_train_orig = y_train * y_std + y_mean\n",
    "    y_test_orig = y_test * y_std + y_mean\n",
    "    y_all_orig = y_norm * y_std + y_mean\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse = mean_squared_error(y_all_orig, y_pred_all)\n",
    "    r2 = r2_score(y_all_orig, y_pred_all)\n",
    "    mae = mean_absolute_error(y_all_orig, y_pred_all)\n",
    "    rmse = mean_squared_error(y_all_orig, y_pred_all, squared=False)\n",
    "\n",
    "    # Generar gráficos para datos de entrenamiento y prueba\n",
    "    gen_graph_neuron(x_train_orig, y_train_orig, x_test_orig, y_test_orig, y_pred_train, y_pred_test, x_n, y_n, 'Modelo de red neuronal', model)\n",
    "\n",
    "    return mse, r2, mae, rmse, y_pred_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'GPA'\n",
    "variables = [\"StudyTimeWeekly\", \"Absences\", \"ParentalSupport\", \"Tutoring\", \"Extracurricular\", \"Sports\", \"Music\"]\n",
    "\n",
    "for y_n in variables:\n",
    "    x = pd.Series(df[x_n])\n",
    "    y = pd.Series(df[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n),\n",
    "                # 'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n),\n",
    "                # 'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n)),\n",
    "    }\n",
    "    comparison = compare_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Cargar una paleta de colores de seaborn\n",
    "# palette = sns.color_palette(\"husl\", n_colors=len(comparison))\n",
    "\n",
    "# def get_color(index):\n",
    "#     return palette[index]\n",
    "\n",
    "# comparison = comparison.iloc[::-1]\n",
    "\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# sns.scatterplot(data=df, x=x_n,  y=y_n, label='Datos originales')\n",
    "\n",
    "# # Agregar las predicciones de cada modelo\n",
    "# for index, row in comparison.iterrows():\n",
    "#     Modelo = row['Modelo']\n",
    "#     mse = row['MSE']\n",
    "#     r2 = row['R2']\n",
    "#     mae = row['MAE']\n",
    "#     rmse = row['RMSE']\n",
    "    \n",
    "#     y_pred = row['Predicciones']\n",
    "#     # plt.plot(x, y_pred, color=random_color(), label=f'{Modelo} (MSE: {mse:.2f}, R2: {r2:.2f})')\n",
    "#     plt.plot(x, y_pred, color=get_color(index), label=f'{Modelo}')\n",
    "\n",
    "\n",
    "# plt.title('Comparación de Modelos de Regresión')\n",
    "# plt.xlabel('GPA')\n",
    "# plt.ylabel('Absences')\n",
    "# plt.legend()\n",
    "# plt.savefig('./graph/Comparacion_de_Modelos_de_Regression.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Clasificación (Predecir una clase - binaria / multinomial) </u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_class(model_dict):\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    for name, (confusion, exactitud, precision, sensibilidad, f1) in model_dict.items():\n",
    "        stats = [name, exactitud, precision, sensibilidad, f1]\n",
    "        results.append(stats)\n",
    "        confusion_matrices[name] = confusion    \n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    return df_results, confusion_matrices\n",
    "\n",
    "def gen_graph_class(df_metricas):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Accuracy', data=df_metricas, ax=ax[0, 0])\n",
    "    ax[0, 0].set_title('Exactitud')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Precision', data=df_metricas, ax=ax[0, 1])\n",
    "    ax[0, 1].set_title('Precision')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Recall', data=df_metricas, ax=ax[1, 0])\n",
    "    ax[1, 0].set_title('Recall')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='F1 Score', data=df_metricas, ax=ax[1, 1])\n",
    "    ax[1, 1].set_title('F1 Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./graph/Modelos de Clasificacion.png')\n",
    "    plt.show()\n",
    "\n",
    "def gen_confusion_matrix(confusion_matrices):\n",
    "    for model_name, confusion in confusion_matrices.items():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Matriz de Confusión - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(f'./graph/Matriz de Confusión - {model_name}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    modelo = RandomForestClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maquina_vectores_soporte(X_train, X_test, y_train, y_test):\n",
    "    modelo = SVC()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbol_decision(X_train, X_test, y_train, y_test):\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def red_neuronal_clasificacion(X_train, X_test, y_train, y_test):\n",
    "    # Determinar el número de clases a partir de los datos\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Convertir etiquetas a formato categórico (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(64, input_dim=input_dim, activation='relu'))  # Capa oculta con 64 neuronas\n",
    "    modelo.add(Dense(64, activation='relu'))  # Otra capa oculta con 64 neuronas\n",
    "    modelo.add(Dense(num_classes, activation='softmax'))  # Capa de salida\n",
    "\n",
    "    # Compilar el modelo\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train_cat, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred_cat = modelo.predict(X_test)\n",
    "    y_pred = y_pred_cat.argmax(axis=1)  # Convertir one-hot encoding a etiquetas\n",
    "\n",
    "    # Calcular métricas\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return confusion, exactitud, precision, sensibilidad, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresión_logistica(X_train, X_test, y_train, y_test):\n",
    "    modelo = LogisticRegression()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(X_train, X_test, y_train, y_test):\n",
    "    modelo = KNeighborsClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    modelo = GaussianNB()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'ParentalEducation'\n",
    "y_n = 'GradeClass'\n",
    "\n",
    "X = df[[x_n]].values\n",
    "y = df[y_n].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Random Forest': random_forest(X_train, X_test, y_train, y_test),\n",
    "    'Máquina de Vectores de Soporte': maquina_vectores_soporte(X_train, X_test, y_train, y_test),\n",
    "    'Árbol de Decisión': arbol_decision(X_train, X_test, y_train, y_test),\n",
    "    'Red Neuronal' : red_neuronal_clasificacion(X_train, X_test, y_train, y_test),\n",
    "    'Regresión Logística': regresión_logistica(X_train, X_test, y_train, y_test),\n",
    "    'K-Nearest Neighbors': k_nearest(X_train, X_test, y_train, y_test),\n",
    "    'Naive Bayes': naive_bayes(X_train, X_test, y_train, y_test)\n",
    "}\n",
    "\n",
    "comparison, confusion_matrices = compare_models_class(models)\n",
    "gen_graph_class(comparison)\n",
    "gen_confusion_matrix(confusion_matrices)\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
