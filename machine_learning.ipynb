{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<u> Aprendizaje Automático  </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('./data/Student_performance_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Regresión (Predecir un número cuantitativo - entero / continuo) </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_dict):\n",
    "    results = []\n",
    "\n",
    "    for name, (mse, r2, mae, rmse, pred) in model_dict.items():\n",
    "        stats = [name, mse, r2, mae, rmse, pred]\n",
    "        results.append(stats)\n",
    "    # df_results = pd.DataFrame(results, columns=['Modelo', 'Error Cuadrático Medio (MSE)', 'Coeficiente de Determinación (R^2)', 'Predicciones'])\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'MSE', 'R2', 'MAE', 'RMSE', 'Predicciones'])\n",
    "    return df_results\n",
    "\n",
    "def gen_graph(x, y_pred, x_name, y_name, title):\n",
    "    plt.figure(figsize=(14,7))\n",
    "\n",
    "    sns.scatterplot(data=df, x=x_name, y=y_name)\n",
    "    plt.plot(x, y_pred, color='red', label='Recta de regresión')\n",
    "    plt.title(title)\n",
    "    plt.savefig('./graph/' + title + '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función de regresión lineal\n",
    "def regresion_lineal(x, y, x_n, y_n):\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x, y)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Generar gráfico\n",
    "    gen_graph(x, y_pred, x_n, y_n, 'Modelo de regresión lineal para predecir los resultados')\n",
    "    return mse, r2, mae, rmse, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_polinomica(x, y, x_n, y_n):\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=10)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "    x_poly = poly.fit_transform(x)\n",
    "\n",
    "    # Crear el modelo de regresión polinómica\n",
    "    poly_model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    poly_model.fit(x_poly, y)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred = poly_model.predict(x_poly)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y, y_poly_pred)\n",
    "    r2_poly = r2_score(y, y_poly_pred)\n",
    "    mae_poly = mean_absolute_error(y, y_poly_pred)\n",
    "    rmse_poly = mean_squared_error(y, y_poly_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    gen_graph(x, y_poly_pred, x_n, y_n, 'Modelo de regresión polinómica para predecir los resultados')\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_ridge(x, y, x_n, y_n):\n",
    "    # Crear el modelo de regresión Ridge\n",
    "    ridge_model = Ridge(alpha=1.0)  # Puedes ajustar alpha para regularización\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    ridge_model.fit(x, y)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_ridge_pred = ridge_model.predict(x)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_ridge = mean_squared_error(y, y_ridge_pred)\n",
    "    r2_ridge = r2_score(y, y_ridge_pred)\n",
    "    mae_ridge = mean_absolute_error(y, y_ridge_pred)\n",
    "    rmse_ridge = mean_squared_error(y, y_ridge_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "\n",
    "    gen_graph(x, y_ridge_pred, x_n, y_n, 'Modelo de regresión Ridge para predecir los resultados')\n",
    "    return mse_ridge, r2_ridge, mae_ridge, rmse_ridge, y_ridge_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion de Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lasso(x, y, x_n, y_n):\n",
    "    # Crear el modelo de regresión Lasso\n",
    "    lasso_model = Lasso(alpha=0.1)  # Puedes ajustar alpha para regularización\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    lasso_model.fit(x, y)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_lasso_pred = lasso_model.predict(x)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_lasso = mean_squared_error(y, y_lasso_pred)\n",
    "    r2_lasso = r2_score(y, y_lasso_pred)\n",
    "    mae_lasso = mean_absolute_error(y, y_lasso_pred)\n",
    "    rmse_lasso = mean_squared_error(y, y_lasso_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    gen_graph(x, y_lasso_pred, x_n, y_n, 'Modelo de regresión Lasso para predecir los resultados')\n",
    "    return mse_lasso, r2_lasso, mae_lasso, rmse_lasso, y_lasso_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regresion_knn(x, y, x_n, y_n):\n",
    "    # Crear el modelo de regresión KNN\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=5)  # Puedes ajustar n_neighbors\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    knn_model.fit(x, y)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_knn_pred = knn_model.predict(x)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_knn = mean_squared_error(y, y_knn_pred)\n",
    "    r2_knn = r2_score(y, y_knn_pred)\n",
    "    mae_knn = mean_absolute_error(y, y_knn_pred)\n",
    "    rmse_knn = mean_squared_error(y, y_knn_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    gen_graph(x, y_knn_pred, x_n, y_n, 'Modelo de regresión KNN para predecir los resultados')\n",
    "    return mse_knn, r2_knn, mae_knn, rmse_knn, y_knn_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con Árbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_tree_regressor(x, y, x_n, y_n):\n",
    "    # Crear el modelo de regresión con árbol de decisión\n",
    "    tree_model = DecisionTreeRegressor(max_depth=5)  # Puedes ajustar max_depth\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    tree_model.fit(x, y)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_tree_pred = tree_model.predict(x)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_tree = mean_squared_error(y, y_tree_pred)\n",
    "    r2_tree = r2_score(y, y_tree_pred)\n",
    "    mae_tree = mean_absolute_error(y, y_tree_pred)\n",
    "    rmse_tree = mean_squared_error(y, y_tree_pred, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    gen_graph(x, y_tree_pred, x_n, y_n, 'Modelo de regresión con Árbol de Decisión para predecir los resultados')\n",
    "    return mse_tree, r2_tree, mae_tree, rmse_tree, y_tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'GPA'\n",
    "y_n = 'Absences'\n",
    "\n",
    "x = pd.Series(df[x_n])\n",
    "y = pd.Series(df[y_n])\n",
    "\n",
    "\n",
    "# Asegurar que x tenga dos dimensiones (n_samples, n_features)\n",
    "x = x.values.reshape(-1, 1)\n",
    "\n",
    "# Asegurar que y tenga dos dimensiones (n_samples, 1)\n",
    "y = y.values.reshape(-1, 1)\n",
    "\n",
    "models = {'Regresión Lineal': regresion_lineal(x, y, x_n, y_n),\n",
    "              'Regresión Polinomica': regresion_polinomica(x, y, x_n, y_n),\n",
    "              'Regresión Ridge': regresion_ridge(x, y, x_n, y_n),\n",
    "              'Regresión Lasso': regresion_lasso(x, y, x_n, y_n),\n",
    "              'Regresión KNN': regresion_knn(x, y, x_n, y_n),\n",
    "              'Árbol de Decisión': decision_tree_regressor(x, y, x_n, y_n),\n",
    "}\n",
    "\n",
    "comparison = compare_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Cargar una paleta de colores de seaborn\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(comparison))\n",
    "\n",
    "def get_color(index):\n",
    "    return palette[index]\n",
    "\n",
    "comparison = comparison.iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(data=df, x=x_n,  y=y_n, label='Datos originales')\n",
    "\n",
    "# Agregar las predicciones de cada modelo\n",
    "for index, row in comparison.iterrows():\n",
    "    Modelo = row['Modelo']\n",
    "    mse = row['MSE']\n",
    "    r2 = row['R2']\n",
    "    mae = row['MAE']\n",
    "    rmse = row['RMSE']\n",
    "    \n",
    "    y_pred = row['Predicciones']\n",
    "    # plt.plot(x, y_pred, color=random_color(), label=f'{Modelo} (MSE: {mse:.2f}, R2: {r2:.2f})')\n",
    "    plt.plot(x, y_pred, color=get_color(index), label=f'{Modelo}')\n",
    "\n",
    "\n",
    "plt.title('Comparación de Modelos de Regresión')\n",
    "plt.xlabel('GPA')\n",
    "plt.ylabel('Absences')\n",
    "plt.legend()\n",
    "plt.savefig('./graph/Comparacion_de_Modelos_de_Regression.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Clasificación (Predecir una clase - binaria / multinomial) </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_class(model_dict):\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    for name, (confusion, exactitud, precision, sensibilidad, f1) in model_dict.items():\n",
    "        stats = [name, exactitud, precision, sensibilidad, f1]\n",
    "        results.append(stats)\n",
    "        confusion_matrices[name] = confusion    \n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    return df_results, confusion_matrices\n",
    "\n",
    "def gen_graph_class(df_metricas):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Accuracy', data=df_metricas, ax=ax[0, 0])\n",
    "    ax[0, 0].set_title('Exactitud')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Precision', data=df_metricas, ax=ax[0, 1])\n",
    "    ax[0, 1].set_title('Precision')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Recall', data=df_metricas, ax=ax[1, 0])\n",
    "    ax[1, 0].set_title('Recall')\n",
    "\n",
    "    sns.barplot(x='Modelo', y='F1 Score', data=df_metricas, ax=ax[1, 1])\n",
    "    ax[1, 1].set_title('F1 Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./graph/Modelos de Clasificacion.png')\n",
    "    plt.show()\n",
    "\n",
    "def gen_confusion_matrix(confusion_matrices):\n",
    "    for model_name, confusion in confusion_matrices.items():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Matriz de Confusión - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(f'./graph/Matriz de Confusión - {model_name}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresión_logistica(X_train, X_test, y_train, y_test):\n",
    "    modelo = LogisticRegression()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbol_decision(X_train, X_test, y_train, y_test):\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    modelo = RandomForestClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maquina_vectores_soporte(X_train, X_test, y_train, y_test):\n",
    "    modelo = SVC()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(X_train, X_test, y_train, y_test):\n",
    "    modelo = KNeighborsClassifier()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    modelo = GaussianNB()\n",
    "    modelo.fit(X_train, y_train)  # Entrenar el modelo\n",
    "    y_pred = modelo.predict(X_test)  # Hacer predicciones\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    exactitud = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    sensibilidad = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return confusion, exactitud, precision, sensibilidad, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'ParentalEducation'\n",
    "y_n = 'GradeClass'\n",
    "\n",
    "X = df[[x_n]].values\n",
    "y = df[y_n].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Regresión Logística': regresión_logistica(X_train, X_test, y_train, y_test),\n",
    "    'Árbol de Decisión': arbol_decision(X_train, X_test, y_train, y_test),\n",
    "    'Random Forest': random_forest(X_train, X_test, y_train, y_test),\n",
    "    'Máquina de Vectores de Soporte': maquina_vectores_soporte(X_train, X_test, y_train, y_test),\n",
    "    'K-Nearest Neighbors': k_nearest(X_train, X_test, y_train, y_test),\n",
    "    'Naive Bayes': naive_bayes(X_train, X_test, y_train, y_test)\n",
    "}\n",
    "\n",
    "comparison, confusion_matrices = compare_models_class(models)\n",
    "gen_graph_class(comparison)\n",
    "gen_confusion_matrix(confusion_matrices)\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
