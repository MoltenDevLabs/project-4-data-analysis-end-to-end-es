{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<u> Aprendizaje Automático  </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from varname import nameof\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Student_performance_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Métodos de transformación y escalado**\n",
    "\n",
    "La preparación de datos para algoritmos de machine learning es un paso importante para asegurar la fiabilidad de los modelos y aumentar su calidad.\n",
    "\n",
    "Para llevar a cabo la transformación y escalado existen diversos métodos y es fundamental comprender cuándo y como utilizarlos. Debido a la naturaleza de los datos de estudiados, el metodo a usar será el StandardScaler.\n",
    "\n",
    "* Escala los datos para que tengan una media de 0 y una desviación estandar de 1.\n",
    "* Se utiliza para centrar y escalar los valores\n",
    "* Se usa cuando los datos se distribuyen normalmente\n",
    "* Para algoritmos sensibles a la escala de los datos, como regresión lineal, regresión logística, SVM, y redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Escalar Datos </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos outliers en las variables numéricas y los eliminamos\n",
    "variables_numericas = ['Age', 'StudyTimeWeekly', 'Absences']\n",
    "df_numericas = df[variables_numericas]\n",
    "\n",
    "def identificar_outliers(df, col_categorica, col_cuantitativa):\n",
    "  outliers = pd.DataFrame() \n",
    "  \n",
    "  for categoria in df[col_categorica].unique(): \n",
    "    data_categoria = df[df[col_categorica] == categoria][col_cuantitativa] \n",
    "    Q1 = data_categoria.quantile(0.25) \n",
    "    Q3 = data_categoria.quantile(0.75) \n",
    "    IQR = Q3 - Q1 \n",
    "    limite_inferior = Q1 - 1.5 * IQR \n",
    "    limite_superior = Q3 + 1.5 * IQR \n",
    "    outliers_categoria = data_categoria[(data_categoria < limite_inferior) | (data_categoria > limite_superior)] \n",
    "    outliers = pd.concat([outliers, outliers_categoria]) \n",
    "  return outliers \n",
    "\n",
    "outliers = identificar_outliers(df, 'GPA', 'Absences') \n",
    "print(f\"Outliers identificados:\\n{outliers}\")\n",
    "\n",
    "indices_outliers = outliers.index\n",
    "df = df.drop(indices_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del StandardScaler en las columnas numericas\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
    "df_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del MinMaxScaler en las columnas\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para comparar modelos en un dataframe\n",
    "def compare_models(model_dict):\n",
    "    results = []\n",
    "\n",
    "    for name, (mse, r2, mae, rmse, pred) in model_dict.items():\n",
    "        stats = [name, mse, r2, mae, rmse]\n",
    "        results.append(stats)\n",
    "    df_results = pd.DataFrame(results, columns=['Modelo', 'MSE', 'R2', 'MAE', 'RMSE'])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Modelos de regresión Escalar Datos </u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresión lineal\n",
    "def regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Añadir jitter a los datos binomiales\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[0].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[0].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[1].plot(X_train, y_pred_train, color='red', label='Recta de regresión')\n",
    "    ax[1].set_title(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion lineal binomial\n",
    "\n",
    "def regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Normalizar los datos de y si el rango es muy pequeño\n",
    "    if np.max(y_train) - np.min(y_train) < 0.1:\n",
    "        scaler = MinMaxScaler()\n",
    "        y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
    "        y_pred_train = scaler.transform(y_pred_train.reshape(-1, 1)).flatten()\n",
    "        y_pred_test = scaler.transform(y_pred_test.reshape(-1, 1)).flatten()\n",
    "        y_n = f'Normalizado {y_n}'\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Asegurarse de que X y y sean arrays unidimensionales\n",
    "        X = X.flatten()\n",
    "        y = y.flatten()\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X)\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "        y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "        # Ajustar tamaño de la ventana para datos con poco rango\n",
    "        window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "        if len(y_sorted) <= window_size:\n",
    "            window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "        \n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la recta de regresión\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', label='Recta de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train, y_pred_train, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test, y_pred_test, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion lineal politomica\n",
    "\n",
    "def regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "\n",
    "    dir = str(f'./graph/1_regresion_lineal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear un modelo de regresión lineal\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones para todos los valores de X\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el primer hasta el último cuadro\n",
    "        X_new = np.linspace(box_limits[0], box_limits[1], 100).reshape(-1, 1)\n",
    "        y_pred_new = model.predict(X_new)\n",
    "\n",
    "        # Graficar la línea de regresión\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Línea de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'1. REGRESIÓN LINEAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "    \n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_lineal_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_lineal_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    else:\n",
    "        return regresion_lineal_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion polinomica category\n",
    "\n",
    "def regresion_polinomica_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=15)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "    \n",
    "    # Crear el modelo de regresión polinómica\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtener el valor mínimo y máximo de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Crear un rango de valores para x para dibujar la curva de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    ax[0].scatter(X_train, y_train_jitter, label='Datos de train', alpha=0.5)\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "    ax[0].set_xlabel(f'{x_n}')\n",
    "    ax[0].set_ylabel(f'{y_n}')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    ax[1].scatter(X_test, y_test_jitter, color='green', label='Datos de test', alpha=0.5)\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "    ax[1].set_xlabel(f'{x_n}')\n",
    "    ax[1].set_ylabel(f'{y_n}')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar el gráfico en la carpeta correspondiente\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion polinomica binomial\n",
    "\n",
    "def regresion_polinomica_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Obtener el valor mínimo y máximo de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Crear un rango de valores para x para dibujar la curva de regresión\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    y_range_pred = model.predict(x_range_poly)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    # Crear función para gráficos de área apilada\n",
    "    def stacked_area_plot(ax, X, y, y_pred, title):\n",
    "        # Asegurarse de que X y y sean arrays unidimensionales\n",
    "        X = X.flatten()\n",
    "        y = y.flatten()\n",
    "        # Clasificar los datos según X\n",
    "        sorted_indices = np.argsort(X)\n",
    "        X_sorted = X[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "        y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "        # Ajustar tamaño de la ventana para datos con poco rango\n",
    "        window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "        if len(y_sorted) <= window_size:\n",
    "            window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "        \n",
    "        proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "        X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "        # Graficar las proporciones\n",
    "        ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "        ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "        # Graficar la curva polinómica de regresión\n",
    "        ax.plot(X_sorted, y_pred_sorted, color='red', label='Curva polinómica de regresión')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    stacked_area_plot(ax[0], X_train, y_train_jitter, y_poly_pred_train, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    stacked_area_plot(ax[1], X_test, y_test_jitter, y_poly_pred_test, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar el gráfico en la carpeta correspondiente\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion polinomica politomica\n",
    "\n",
    "def regresion_polinomica_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n, poly_degree=15):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/2_regresion_polinomica/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)  # Cambiar degree para ajustar la complejidad del modelo\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)  # Cambiar fit_transform a transform para datos de test\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train.reshape(-1, 1)], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # Obtener los valores mínimos y máximos de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Ajustar los límites de la línea de regresión para comenzar y terminar en las cajas\n",
    "        x_start = max(x_min, box_limits[0])\n",
    "        x_end = min(x_max, box_limits[1])\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el borde de la primera caja hasta el borde de la última caja\n",
    "        X_new = np.linspace(x_start, x_end, 100).reshape(-1, 1)\n",
    "        y_pred_new = model.predict(poly.transform(X_new))\n",
    "\n",
    "        # Graficar la curva de regresión polinómica\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Curva Polinómica de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'2. REGRESIÓN POLINÓMICA Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_polinomica_binomial(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_polinomica_politomica(X_train, X_test, y_train, y_test, x_n, y_n, df_n)\n",
    "    else:\n",
    "        return regresion_polinomica_category(X_train, X_test, y_train, y_test, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de regresion neuronal category\n",
    "\n",
    "def gen_graph_neuron(x_train, y_train, x_test, y_test, y_pred_train, y_pred_test, x_n, y_n, model, df_n):\n",
    "\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/3_regresion_neuronal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  \n",
    "\n",
    "    x_min = min(x_train.min(), x_test.min())\n",
    "    x_max = max(x_train.max(), x_test.max())\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "\n",
    "    x_range_norm = (x_range - np.mean(x_train)) / np.std(x_train)\n",
    "    y_range_pred_norm = model.predict(x_range_norm)\n",
    "    y_range_pred = y_range_pred_norm * np.std(y_train) + np.mean(y_train)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    ax[0].scatter(x_train, y_train_jitter, label='Datos de entrenamiento', alpha=0.5)\n",
    "    ax[0].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[0].set_title(f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "    ax[0].set_xlabel(x_n)\n",
    "    ax[0].set_ylabel(y_n)\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].scatter(x_test, y_test_jitter, color='green', label='Datos de prueba', alpha=0.5)\n",
    "    ax[1].plot(x_range, y_range_pred, color='red', label='Curva de regresión')\n",
    "    ax[1].set_title(f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "    ax[1].set_xlabel(x_n)\n",
    "    ax[1].set_ylabel(y_n)\n",
    "    ax[1].legend()\n",
    "\n",
    "    file = str(f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "\n",
    "def regresion_neuronal_category(x, y, x_n, y_n, df_n):\n",
    "    x = np.array(x).reshape(-1, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    x_mean = np.mean(x)\n",
    "    x_std = np.std(x)\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    x_norm = (x - x_mean) / x_std\n",
    "    y_norm = (y - y_mean) / y_std\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_norm, y_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(x_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.2, verbose=0)\n",
    "\n",
    "    y_pred_train_norm = model.predict(x_train)\n",
    "    y_pred_test_norm = model.predict(x_test)\n",
    "    y_pred_all_norm = model.predict(x_norm)\n",
    "\n",
    "    y_pred_train = y_pred_train_norm * y_std + y_mean\n",
    "    y_pred_test = y_pred_test_norm * y_std + y_mean\n",
    "    y_pred_all = y_pred_all_norm * y_std + y_mean\n",
    "\n",
    "    x_train_orig = x_train * x_std + x_mean\n",
    "    x_test_orig = x_test * x_std + x_mean\n",
    "    x_all_orig = x_norm * x_std + x_mean\n",
    "\n",
    "    y_train_orig = y_train * y_std + y_mean\n",
    "    y_test_orig = y_test * y_std + y_mean\n",
    "    y_all_orig = y_norm * y_std + y_mean\n",
    "\n",
    "    mse = mean_squared_error(y_all_orig, y_pred_all)\n",
    "    r2 = r2_score(y_all_orig, y_pred_all)\n",
    "    mae = mean_absolute_error(y_all_orig, y_pred_all)\n",
    "    rmse = mean_squared_error(y_all_orig, y_pred_all, squared=False)\n",
    "\n",
    "    gen_graph_neuron(x_train_orig, y_train_orig, x_test_orig, y_test_orig, y_pred_train, y_pred_test, x_n, y_n, model, df_n)\n",
    "    return mse, r2, mae, rmse, y_pred_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion neuronal binomial\n",
    "\n",
    "def stacked_area_plot(ax, X, y, y_pred, title, x_n, y_n):\n",
    "    # Asegurarse de que X y y sean arrays unidimensionales\n",
    "    X = X.flatten()\n",
    "    y = y.flatten()\n",
    "    # Clasificar los datos según X\n",
    "    sorted_indices = np.argsort(X)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "    # Ajustar tamaño de la ventana para datos con poco rango\n",
    "    window_size = min(50, len(y_sorted) // 2)  # Tamaño de ventana adaptativo\n",
    "    if len(y_sorted) <= window_size:\n",
    "        window_size = len(y_sorted) - 1  # Asegúrate de que la ventana no sea más grande que el número de muestras\n",
    "    \n",
    "    proportions_0 = [np.mean(y_sorted[i:i+window_size] <= 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "    proportions_1 = [np.mean(y_sorted[i:i+window_size] > 0.5) for i in range(len(y_sorted) - window_size + 1)]\n",
    "    X_windows = X_sorted[:len(proportions_0)]\n",
    "\n",
    "    # Graficar las proporciones\n",
    "    ax.fill_between(X_windows.flatten(), proportions_0, label=f'<= 0.5 {y_n}', alpha=0.5)\n",
    "    ax.fill_between(X_windows.flatten(), proportions_1, label=f'> 0.5 {y_n}', alpha=0.5)\n",
    "\n",
    "    # Graficar la curva polinómica de regresión\n",
    "    ax.plot(X_sorted, y_pred_sorted, color='red', label='Curva de regresión neuronal')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_n)\n",
    "    ax.set_ylabel(y_n)\n",
    "    ax.legend()\n",
    "\n",
    "def gen_graph_neuron_binomial(x_train, y_train, x_test, y_test, y_pred_train, y_pred_test, x_n, y_n, model, df_n):\n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/3_regresion_neuronal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Obtener el rango de x para la curva de regresión\n",
    "    x_min = min(x_train.min(), x_test.min())\n",
    "    x_max = max(x_train.max(), x_test.max())\n",
    "    x_range = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "\n",
    "    x_range_norm = (x_range - np.mean(x_train)) / np.std(x_train)\n",
    "    y_range_pred_norm = model.predict(x_range_norm)\n",
    "    y_range_pred = y_range_pred_norm * np.std(y_train) + np.mean(y_train)\n",
    "\n",
    "    # Añadir jitter a los datos\n",
    "    jitter_strength = 0.02\n",
    "    y_train_jitter = y_train + np.random.uniform(-jitter_strength, jitter_strength, y_train.shape)\n",
    "    y_test_jitter = y_test + np.random.uniform(-jitter_strength, jitter_strength, y_test.shape)\n",
    "\n",
    "    # Crear una figura con dos subgráficos\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "    # Primer subgráfico: Datos de entrenamiento\n",
    "    stacked_area_plot(ax[0], x_train, y_train_jitter, y_pred_train, \n",
    "                       f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - train. DF: {df_n}',\n",
    "                       x_n, y_n)\n",
    "\n",
    "    # Segundo subgráfico: Datos de prueba\n",
    "    stacked_area_plot(ax[1], x_test, y_test_jitter, y_pred_test, \n",
    "                       f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - test. DF: {df_n}',\n",
    "                       x_n, y_n)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "\n",
    "def regresion_neuronal_binomial(x, y, x_n, y_n, df_n):\n",
    "    # Convertir a arrays y hacer reshape\n",
    "    x = np.array(x).reshape(-1, 1)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Dividir los datos en entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalizar los datos\n",
    "    x_mean = np.mean(x_train)\n",
    "    x_std = np.std(x_train)\n",
    "    y_mean = np.mean(y_train)\n",
    "    y_std = np.std(y_train)\n",
    "\n",
    "    x_train_norm = (x_train - x_mean) / x_std\n",
    "    x_test_norm = (x_test - x_mean) / x_std\n",
    "\n",
    "    # Definir y entrenar el modelo de red neuronal\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(x_train_norm.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(x_train_norm, y_train, epochs=100, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred_train_norm = model.predict(x_train_norm)\n",
    "    y_pred_test_norm = model.predict(x_test_norm)\n",
    "    y_pred_all_norm = model.predict((np.concatenate([x_train, x_test]) - x_mean) / x_std)\n",
    "\n",
    "    # Desnormalizar las predicciones\n",
    "    y_pred_train = y_pred_train_norm * y_std + y_mean\n",
    "    y_pred_test = y_pred_test_norm * y_std + y_mean\n",
    "    y_pred_all = y_pred_all_norm * y_std + y_mean\n",
    "\n",
    "    # Desnormalizar los datos\n",
    "    x_train_orig = x_train\n",
    "    x_test_orig = x_test\n",
    "    x_all_orig = np.concatenate([x_train, x_test])\n",
    "\n",
    "    y_train_orig = y_train\n",
    "    y_test_orig = y_test\n",
    "    y_all_orig = np.concatenate([y_train, y_test])\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse = mean_squared_error(y_all_orig, y_pred_all)\n",
    "    r2 = r2_score(y_all_orig, y_pred_all)\n",
    "    mae = mean_absolute_error(y_all_orig, y_pred_all)\n",
    "    rmse = mean_squared_error(y_all_orig, y_pred_all, squared=False)\n",
    "\n",
    "    # Generar gráficos\n",
    "    gen_graph_neuron_binomial(x_train_orig, y_train_orig, x_test_orig, y_test_orig, y_pred_train, y_pred_test, x_n, y_n, model, df_n)\n",
    "\n",
    "    return mse, r2, mae, rmse, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de regresion neuronal politomica\n",
    "\n",
    "def regresion_neuronal_politomica(x, y, x_n, y_n, df_n, poly_degree=15, hidden_layer_sizes=(100,), test_size=0.2):\n",
    "    # Asegúrate de que x e y sean arrays de NumPy\n",
    "    x = np.asarray(x).reshape(-1, 1) if x.ndim == 1 else np.asarray(x)\n",
    "    y = np.asarray(y).reshape(-1, 1) if y.ndim == 1 else np.asarray(y)\n",
    "\n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)\n",
    "    \n",
    "    # Crear el directorio para guardar los gráficos\n",
    "    dir = str(f'./graph/3_regresion_neuronal/{df_n}/')\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=poly_degree)\n",
    "\n",
    "    # Transformar los datos\n",
    "    x_poly_train = poly.fit_transform(X_train)\n",
    "    x_poly_test = poly.transform(X_test)\n",
    "\n",
    "    # Crear el modelo de red neuronal\n",
    "    model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, max_iter=1000, random_state=0)\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    model.fit(x_poly_train, y_train.ravel())  # .ravel() convierte a una 1D array\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_poly_pred_train = model.predict(x_poly_train)\n",
    "    y_poly_pred_test = model.predict(x_poly_test)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    mse_poly = mean_squared_error(y_test, y_poly_pred_test)\n",
    "    r2_poly = r2_score(y_test, y_poly_pred_test)\n",
    "    mae_poly = mean_absolute_error(y_test, y_poly_pred_test)\n",
    "    rmse_poly = mean_squared_error(y_test, y_poly_pred_test, squared=False)  # squared=False returns the RMSE\n",
    "\n",
    "    # Preparar datos para gráficos\n",
    "    train_data = np.concatenate([X_train, y_train], axis=1)\n",
    "    test_data = np.concatenate([X_test, y_test], axis=1)\n",
    "\n",
    "    # Obtener los valores mínimos y máximos de x para el rango de valores\n",
    "    x_min = X_train.min()\n",
    "    x_max = X_train.max()\n",
    "\n",
    "    # Generar gráfico\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))  # Crear una figura con dos subgráficos\n",
    "\n",
    "    def boxplot_with_regression(ax, data, title):\n",
    "        X = data[:, 0].reshape(-1, 1)\n",
    "        y = data[:, 1]\n",
    "\n",
    "        # Graficar el gráfico de cajas\n",
    "        sns.boxplot(x=y, y=X.flatten(), ax=ax, palette='Set2')\n",
    "\n",
    "        # Determinar los límites del gráfico de cajas\n",
    "        box_limits = ax.get_xlim()\n",
    "\n",
    "        # Ajustar los límites de la línea de regresión para comenzar y terminar en las cajas\n",
    "        x_start = max(x_min, box_limits[0])\n",
    "        x_end = min(x_max, box_limits[1])\n",
    "\n",
    "        # Crear nuevos puntos de X para la línea de regresión desde el borde de la primera caja hasta el borde de la última caja\n",
    "        X_new = np.linspace(x_start, x_end, 100).reshape(-1, 1)\n",
    "        X_poly_new = poly.transform(X_new)\n",
    "        y_pred_new = model.predict(X_poly_new)\n",
    "\n",
    "        # Graficar la curva de regresión neuronal\n",
    "        ax.plot(X_new, y_pred_new, color='red', linewidth=2, label='Curva Neuronal de Regresión')\n",
    "\n",
    "        # Configuración del gráfico\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{x_n}')\n",
    "        ax.set_ylabel(f'{y_n}')\n",
    "        ax.legend(title='Leyenda')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Primer subgráfico: Datos de train\n",
    "    boxplot_with_regression(ax[0], train_data, f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - train. DF: {df_n}')\n",
    "\n",
    "    # Segundo subgráfico: Datos de test\n",
    "    boxplot_with_regression(ax[1], test_data, f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} - test. DF: {df_n}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file = str(f'3. REGRESIÓN NEURONAL Relación entre {x_n} y {y_n} DF: {df_n}.png')\n",
    "    plt.savefig(dir + file)\n",
    "    #plt.show()\n",
    "\n",
    "    return mse_poly, r2_poly, mae_poly, rmse_poly, y_poly_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_neuronal(x, y, x_n, y_n, df_n):\n",
    "    if y_n == \"Tutoring\" or y_n == \"Extracurricular\" or y_n == \"Sports\" or y_n == \"Music\":\n",
    "        return regresion_neuronal_binomial(x, y, x_n, y_n, df_n)\n",
    "    elif y_n == \"ParentalSupport\":\n",
    "        return regresion_neuronal_politomica(x, y, x_n, y_n, df_n)\n",
    "    else:\n",
    "        return regresion_neuronal_category(x, y, x_n, y_n, df_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Programa principal </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = 'GPA'\n",
    "variables = [\"StudyTimeWeekly\", \"Absences\", \"ParentalSupport\", \"Tutoring\", \"Extracurricular\", \"Sports\", \"Music\"]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for y_n in variables:\n",
    "    x = pd.Series(df[x_n])\n",
    "    y = pd.Series(df[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\n",
    "    'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n), nameof(df)),\n",
    "    }\n",
    "    comparison_df = compare_models(models)\n",
    "\n",
    "    x = pd.Series(df_standard[x_n])\n",
    "    y = pd.Series(df_standard[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_standard)),\n",
    "    'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_standard)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n), nameof(df_standard)),\n",
    "    }\n",
    "    comparison_df_standard = compare_models(models)\n",
    "\n",
    "    x = pd.Series(df_minmax[x_n])\n",
    "    y = pd.Series(df_minmax[y_n])\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x.values.reshape(-1, 1), y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {'Regresión Lineal': regresion_lineal(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_minmax)),\n",
    "    'Regresión Polinomica': regresion_polinomica(X_train, X_test, y_train, y_test, x_n, y_n, nameof(df_minmax)),\n",
    "    'Regresión Neuronal': regresion_neuronal(x, y, x_n, str(y_n), nameof(df_minmax)),\n",
    "    }\n",
    "    comparison_df_minmax = compare_models(models)\n",
    "\n",
    "    results_dict[f'df_{y_n}'] = {\n",
    "        'comparison_df': comparison_df,\n",
    "        'comparison_df_standard': comparison_df_standard,\n",
    "        'comparison_df_minmax': comparison_df_minmax\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Importar resultados </u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los resultados a un archivo CSV\n",
    "# Abre un archivo en modo de escritura CSV\n",
    "with open('resultados.csv', 'w', newline='') as file:\n",
    "    # Itera sobre todas las entradas en el diccionario\n",
    "    for variable_name, results in results_dict.items():\n",
    "        # Escribe los resultados sin normalizar\n",
    "        file.write(f\"Resultados para {variable_name} (sin normalizar):\\n\")\n",
    "        results['comparison_df'].to_csv(file, index=False)\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "        # Escribe los resultados estandarizados\n",
    "        file.write(f\"Resultados para {variable_name} (estandarizado):\\n\")\n",
    "        results['comparison_df_standard'].to_csv(file, index=False)\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "        # Escribe los resultados normalizados Min-Max\n",
    "        file.write(f\"Resultados para {variable_name} (normalizado Min-Max):\\n\")\n",
    "        results['comparison_df_minmax'].to_csv(file, index=False)\n",
    "        file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "print(\"Los resultados se han exportado a 'resultados.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta los resultados a un archivo de texto\n",
    "# Abre un archivo en modo de escritura\n",
    "with open('resultados.txt', 'w') as file:\n",
    "    # Itera sobre todas las entradas en el diccionario\n",
    "    for variable_name, results in results_dict.items():\n",
    "        # Escribe los resultados en el archivo\n",
    "        file.write(f\"Resultados para {variable_name} (sin normalizar):\\n\")\n",
    "        file.write(results['comparison_df'].to_string())\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "        file.write(f\"Resultados para {variable_name} (estandarizado):\\n\")\n",
    "        file.write(results['comparison_df_standard'].to_string())\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "        file.write(f\"Resultados para {variable_name} (normalizado Min-Max):\\n\")\n",
    "        file.write(results['comparison_df_minmax'].to_string())\n",
    "        file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "print(\"Los resultados se han exportado a 'resultados.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Análisis de datos </u>**\n",
    "\n",
    "Los datos presentados permiten extraer diversas inferencias sobre el funcionamiento de modelos de regresión lineal, polinomial y neuronal en conjuntos de datos variados y con distintas técnicas de normalización. A continuación se detallan las observaciones más destacadas:\n",
    "\n",
    "\n",
    "**<u> Conjunto de datos sobre tiempo de estudio semanal: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo basado en redes neuronales muestra superioridad (Índice de error 30.33, Coeficiente predictivo 0.048).\n",
    "- Estandarizado: El enfoque basado en redes neuronales mantiene su ventaja (Índice de error 0.95, Coeficiente predictivo 0.048).\n",
    "- Normalización Min-Max: El método basado en redes neuronales sigue liderando (Índice de error 0.076, Coeficiente predictivo 0.048).\n",
    "\n",
    "En general, el enfoque basado en redes neuronales demuestra un rendimiento superior en todas las técnicas de preparación de datos para este conjunto.\n",
    "\n",
    "**<u> Conjunto de datos sobre ausencias: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo polinomial destaca (Índice de error 9.69, Coeficiente predictivo 0.865).\n",
    "- Estandarizado: El enfoque polinomial mantiene su liderazgo (Índice de error 0.136, Coeficiente predictivo 0.865).\n",
    "- Normalización Min-Max: El método polinomial sigue siendo el más efectivo (Índice de error 0.0115, Coeficiente predictivo 0.865).\n",
    "\n",
    "El enfoque polinomial muestra un rendimiento superior en todas las técnicas de preparación de datos para este conjunto.\n",
    "\n",
    "**<u> Conjunto de datos sobre apoyo familiar: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo polinomial tiene una ligera ventaja (Índice de error 1.226, Coeficiente predictivo 0.0658). El enfoque basado en redes muestra un rendimiento inferior.\n",
    "- Estandarizado: El método polinomial mantiene su superioridad (Índice de error 0.972, Coeficiente predictivo 0.0658).\n",
    "- Normalización Min-Max: El enfoque polinomial continúa liderando (Índice de error 0.0766, Coeficiente predictivo 0.0658).\n",
    "\n",
    "El modelo polinomial demuestra ser consistentemente superior para este conjunto de datos.\n",
    "\n",
    "**<u> Conjunto de datos sobre tutoría: </u>**\n",
    "\n",
    "- Sin Normalizar: El enfoque polinomial muestra el mejor rendimiento (Índice de error 0.205, Coeficiente predictivo 0.0379).\n",
    "- Estandarizado: El modelo polinomial mantiene su ventaja (Índice de error 0.975, Coeficiente predictivo 0.0379).\n",
    "- Normalización Min-Max: El método polinomial sigue siendo el más efectivo (Índice de error 0.205, Coeficiente predictivo 0.0379).\n",
    "\n",
    "El enfoque polinomial demuestra un rendimiento superior en todas las técnicas de preparación de datos para este conjunto.\n",
    "\n",
    "**<u> Conjunto de datos sobre actividades extracurriculares: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo lineal muestra una leve superioridad (Índice de error 0.239, Coeficiente predictivo 0.0031).\n",
    "- Estandarizado: El enfoque basado en redes toma la delantera (Índice de error 0.986, Coeficiente predictivo 0.0133).\n",
    "- Normalización Min-Max: El método lineal recupera su ventaja (Índice de error 0.239, Coeficiente predictivo 0.0031).\n",
    "\n",
    "Para este conjunto, los enfoques lineal y basado en redes muestran resultados competitivos, con una ligera ventaja del lineal en dos de las tres técnicas de preparación de datos.\n",
    "\n",
    "**<u> Conjunto de datos sobre actividades físicas: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo lineal muestra una leve superioridad (Índice de error 0.206, Coeficiente predictivo -0.0013).\n",
    "- Estandarizado: El enfoque basado en redes destaca (Índice de error 0.993, Coeficiente predictivo 0.0068).\n",
    "- Normalización Min-Max: El método lineal vuelve a destacar (Índice de error 0.206, Coeficiente predictivo -0.0013).\n",
    "\n",
    "Para este conjunto, los enfoques lineal y basado en redes ofrecen resultados cercanos, con una sutil ventaja del lineal en dos de las tres técnicas de preparación de datos.\n",
    "\n",
    "**<u> Conjunto de datos sobre música: </u>**\n",
    "\n",
    "- Sin Normalizar: El modelo lineal muestra una leve superioridad (Índice de error 0.157, Coeficiente predictivo 0.0097).\n",
    "- Estandarizado: El enfoque polinomial toma la delantera (Índice de error 0.993, Coeficiente predictivo 0.0095).\n",
    "- Normalización Min-Max: El método polinomial mantiene su ventaja (Índice de error 0.157, Coeficiente predictivo 0.0095).\n",
    "\n",
    "Para este conjunto, los enfoques lineal y polinomial muestran resultados competitivos, con una ligera ventaja del polinomial en dos de las tres técnicas de preparación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<u> Conclusiones </u>**\n",
    "\n",
    "\n",
    "Conclusiones generales:\n",
    "\n",
    "- Regresión Neuronal: Sobresale en el conjunto de datos de tiempo de estudio semanal.\n",
    "- Regresión Polinomial: Muestra mejor rendimiento en los conjuntos de ausencias, apoyo parental, tutoría y música.\n",
    "- Regresión Lineal: Presenta un desempeño competitivo en los conjuntos de actividades extracurriculares y deportes.\n",
    "\n",
    "Es relevante señalar que la normalización y estandarización de los datos pueden impactar significativamente en el rendimiento de los modelos, y la elección del modelo más adecuado puede variar según el preprocesamiento aplicado a los datos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
